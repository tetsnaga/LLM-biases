{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccaeccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee73bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL = \"deepseek-r1:1.5b\"     \n",
    "TEMPERATURE = 0.2\n",
    "PERSONAS_CSV = \"Data/synthetic_climate_personas.csv\"\n",
    "CLAIMS_JSON = \"Data/climate-fever-dataset.json\"\n",
    "OUT_CSV = \"agents_claim_outputs.csv\"\n",
    "N_PERSONAS   = 4\n",
    "N_CLAIMS     = 2\n",
    "SEED         = 42   # set None to keep original order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe890313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Personas: 100%|██████████| 4/4 [00:41<00:00, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 8 records -> outputs/agent_claim_outputs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_TMPL = \"\"\"You are simulating the thought process of a person with the following persona:\n",
    "\n",
    "{PERSONA_DESCRIPTION}\n",
    "\n",
    "Your task is to evaluate claims about climate change.\n",
    "- Always respond as this person would, considering their background, values, and beliefs.\n",
    "- You cannot access new facts beyond what is given.\n",
    "- Your reasoning may be influenced by your prior beliefs (this is natural).\n",
    "- Be consistent in personality and tone across all answers.\n",
    "\n",
    "For each claim you see, you will:\n",
    "1. Read the claim carefully.\n",
    "2. Decide whether you accept the claim or not.\n",
    "3. Give your stance on whether you support or not support the claim. You should respond by either \"Support\" or \"Not Support\".\n",
    "4. Give your stance on climate chnage existance . Your should respond by only on of the followings: \"Strongly disagree\", \"Slightly Disagree\", \"Neutral\", \"Slightly Agree\" and \"Strongly Agree\".\n",
    "\"\"\"\n",
    "\n",
    "CLAIM_TMPL = \"\"\"Claim: {CLAIM_TEXT},\n",
    "Given above claim return : \n",
    "1. your stance on whether you support or not support the claim. You should respond by either \"Support\" or \"Not Support\".\n",
    "4. your stance on climate chnage existance . Your should respond by only on of the followings: \"Strongly disagree\", \"Slightly Disagree\", \"Neutral\", \"Slightly Agree\" and \"Strongly Agree\".\n",
    "\n",
    "Your output should be strictly in the following format : \n",
    "{{\n",
    "\"climateChnageStance\" : [your stances],\n",
    "\"claimStance\" : [your stance]\n",
    "}}\"\"\"\n",
    "\n",
    "REGEX_HINT = r'^\\{\"climateChnageStance\":\"(Strongly disagree|Slightly Disagree|Neutral|Slightly Agree|Strongly Agree)\",\"claimStance\":\"(Support|Not Support)\"\\}$'\n",
    "\n",
    "BELIEF_ALLOWED = {\n",
    "    \"Strongly disagree\",\"Slightly Disagree\",\"Neutral\",\"Slightly Agree\",\"Strongly Agree\"\n",
    "}\n",
    "CLAIM_ALLOWED = {\"Support\",\"Not Support\"}\n",
    "\n",
    "def build_persona_description(row: pd.Series) -> str:\n",
    "    return (\n",
    "        f\"- PersonaID: {row.get('PersonaID')}\\n\"\n",
    "        f\"- AgeGroup: {row.get('AgeGroup')}\\n\"\n",
    "        f\"- Gender: {row.get('Gender')}\\n\"\n",
    "        f\"- EducationLevel: {row.get('EducationLevel')}\\n\"\n",
    "        f\"- OccupationSector: {row.get('OccupationSector')}\\n\"\n",
    "        f\"- Region: {row.get('Region')}\\n\"\n",
    "        f\"- PoliticalIdeology: {row.get('PoliticalIdeology')}\\n\"\n",
    "        f\"- Trust_ScienceInstitutions: {row.get('Trust_ScienceInstitutions')}\\n\"\n",
    "        f\"- Belief_ClimateExists: {row.get('Belief_ClimateExists')}\\n\"\n",
    "        f\"- Belief_HumanContribution: {row.get('Belief_HumanContribution')}\\n\"\n",
    "        f\"- Emotional_WorryAboutClimate: {row.get('Emotional_WorryAboutClimate')}\\n\"\n",
    "        f\"- BehaviouralOrientation: {row.get('BehaviouralOrientation')}\\n\"\n",
    "        f\"- SocialConnectivity: {row.get('SocialConnectivity')}\"\n",
    "    )\n",
    "\n",
    "def chat_once(system_msg: str, user_msg: str) -> str:\n",
    "    r = ollama.chat(\n",
    "        model=MODEL,\n",
    "        options={\"temperature\": TEMPERATURE},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg + f\"\\n\\nReturn JSON matching this regex: {REGEX_HINT}\"},\n",
    "        ],\n",
    "    )\n",
    "    return r[\"message\"][\"content\"].strip()\n",
    "\n",
    "def coerce_json(text: str) -> Dict[str, Any]:\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "    except Exception:\n",
    "        s, e = text.find(\"{\"), text.rfind(\"}\")\n",
    "        if s == -1 or e == -1 or e <= s:\n",
    "            raise ValueError(f\"No JSON object found in: {text[:120]}...\")\n",
    "        obj = json.loads(text[s:e+1])\n",
    "\n",
    "    claim = str(obj.get(\"claimStance\", \"\")).strip()\n",
    "    belief = str(obj.get(\"climateChnageStance\", \"\")).strip()\n",
    "\n",
    "    if claim not in CLAIM_ALLOWED:\n",
    "        claim = \"Support\" if \"support\" in claim.lower() and \"not\" not in claim.lower() else \"Not Support\"\n",
    "    canon_map = {v.lower(): v for v in BELIEF_ALLOWED}\n",
    "    belief = canon_map.get(belief.lower(), \"Neutral\")\n",
    "\n",
    "    return {\"claimStance\": claim, \"climateChnageStance\": belief}\n",
    "\n",
    "def load_claims_with_label(path: str):\n",
    "    \"\"\"\n",
    "    Robustly map common key names -> {claim_id, claim_text, claim_label}.\n",
    "    Skips entries without a usable claim text.\n",
    "    \"\"\"\n",
    "    raw = json.loads(Path(path).read_text())\n",
    "    out = []\n",
    "    for it in raw:\n",
    "        claim_text = (\n",
    "            it.get(\"claim\") or it.get(\"claim_text\") or it.get(\"statement\") or it.get(\"text\") or \"\"\n",
    "        )\n",
    "        if not claim_text:\n",
    "            continue\n",
    "        out.append({\n",
    "            \"claim_id\": it.get(\"claim_id\") or it.get(\"id\"),\n",
    "            \"claim_text\": claim_text,\n",
    "            \"claim_label\": it.get(\"label\") or it.get(\"claim_label\") or it.get(\"verdict\") or it.get(\"stance\")\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    personas = pd.read_csv(PERSONAS_CSV)\n",
    "    claims = load_claims_with_label(CLAIMS_JSON)\n",
    "\n",
    "    # (Optional) sample a small test slice\n",
    "    if SEED is not None:\n",
    "        personas = personas.sample(n=min(N_PERSONAS, len(personas)), random_state=SEED)\n",
    "        random.seed(SEED)\n",
    "        claims = (\n",
    "            pd.DataFrame(claims)\n",
    "            .sample(n=min(N_CLAIMS, len(claims)), random_state=SEED)\n",
    "            .to_dict(orient=\"records\")\n",
    "        )\n",
    "    else:\n",
    "        personas = personas.head(N_PERSONAS)\n",
    "        claims = claims[:N_CLAIMS]\n",
    "\n",
    "    # IMPORTANT: do NOT re-filter claims again (that was causing empty lists)\n",
    "    # keep 'claims' as a list of dicts with keys: claim_id, claim_text, claim_label\n",
    "\n",
    "    records = []\n",
    "    for _, prow in tqdm(personas.iterrows(), total=len(personas), desc=\"Personas\"):\n",
    "        persona_desc = build_persona_description(prow)\n",
    "        system_msg = SYSTEM_TMPL.replace(\"{PERSONA_DESCRIPTION}\", persona_desc)\n",
    "\n",
    "        for c in claims:\n",
    "            user_msg = CLAIM_TMPL.replace(\"{CLAIM_TEXT}\", str(c[\"claim_text\"]))\n",
    "            raw = chat_once(system_msg, user_msg)\n",
    "            try:\n",
    "                parsed = coerce_json(raw)\n",
    "            except Exception:\n",
    "                parsed = {\"claimStance\": \"Not Support\", \"climateChnageStance\": \"Neutral\"}\n",
    "\n",
    "            # flat result row (optional)\n",
    "            # results.append(...)\n",
    "\n",
    "            # JSON record (single-file JSON output)\n",
    "            records.append({\n",
    "                \"persona_id\": prow.get(\"PersonaID\"),\n",
    "                \"belief_climate_exists\": prow.get(\"Belief_ClimateExists\"),\n",
    "                \"claim_id\": c[\"claim_id\"],\n",
    "                \"claim\": c[\"claim_text\"],\n",
    "                \"claim_label\": c.get(\"claim_label\"),\n",
    "                \"llm_responses\": {\n",
    "                    \"claimStance\": parsed[\"claimStance\"],\n",
    "                    \"climateChnageStance\": parsed[\"climateChnageStance\"]\n",
    "                },\n",
    "                \"raw\": raw  # keep for audit/debug; remove if you prefer smaller files\n",
    "            })\n",
    "\n",
    "    # Write ONE JSON file (array)\n",
    "    out_path = Path(\"outputs/agent_claim_outputs.json\")\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Saved {len(records)} records -> {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f06351c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f619cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMBiases_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
