{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe68210-4a20-4266-9ef2-1d2e99c2b5f7",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd5cd9b-d555-46e5-8edb-5d41658296bf",
   "metadata": {},
   "source": [
    "First, we load the result file containing the experimental outputs.\n",
    "\n",
    "The dataset should include the following columns:\n",
    "\n",
    "| Column Name | Description |\n",
    "|--------------|-------------|\n",
    "| **PersonaID** | Unique identifier of each persona. |\n",
    "| **BeliefClimateExists** | Persona’s prior belief (1–5 scale) on whether climate change exists. |\n",
    "| **ClaimID** | Identifier of the presented claim. |\n",
    "| **ClaimStanceLabel** | Whether the claim *supports* or *refutes* the existence of climate change. |\n",
    "| **EvidencesVerdict** | Strength of evidence behind the claim (`SUPPORTS`, `REFUTES`, or `NOT_ENOUGH_INFO`). |\n",
    "| **Evidence** | Text of the evidence used for the verdict. |\n",
    "| **ClaimEntropy** | Information entropy of the claim (uncertainty measure). |\n",
    "| **ModelDecisionOfClaim** | Model’s final decision on the claim (`Accept`, `Refute`, `Neutral`). |\n",
    "| **ModelDecisionOfClaim_Reason** | Model’s reasoning behind its decision. |\n",
    "| **ModelBeliefClimateExists** | Updated belief (1–5 scale) after reading the claim. |\n",
    "| **ModelBeliefClimateExists_Reason** | Model’s reasoning behind the updated belief. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59f79a00-9ac6-42d1-8a72-f630dc4cd4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change the file name here\n",
    "df = pd.read_csv(\"data/result_level_4.csv\")\n",
    "\n",
    "# Filter out invalid rows\n",
    "mask = (\n",
    "    (df[\"ModelDecisionOfClaim_Reason\"].notna() & ~df[\"ModelDecisionOfClaim_Reason\"].str.contains(\"model error\", case=False, na=False)) |\n",
    "    (df[\"ModelBeliefClimateExists_Reason\"].notna() & ~df[\"ModelBeliefClimateExists_Reason\"].str.contains(\"model error\", case=False, na=False))\n",
    ")\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "# Map the textual responses to numbers\n",
    "df[\"BeliefClimateExists_num\"] = df[\"BeliefClimateExists\"].map({\n",
    "    \"Strongly disagree\": -2, \n",
    "    \"Strongly Disagree\": -2,\n",
    "    \"Slightly disagree\": -1,\n",
    "    \"Slightly Disagree\": -1,\n",
    "    \"Neutral\": 0, \n",
    "    \"Slightly agree\": 1,\n",
    "    \"Slightly Agree\": 1,\n",
    "    \"Strongly agree\": 2,\n",
    "    \"Strongly Agree\": 2\n",
    "})\n",
    "df[\"ClaimStanceLabel_num\"] = df[\"ClaimStanceLabel\"].map({\"REFUTES\": 0, \"SUPPORTS\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715bacde-b8b2-4e1f-bce1-96c409c76d16",
   "metadata": {},
   "source": [
    "Alignment captures whether the user’s prior belief matches the claim stance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e70e7dbd-f7f3-4f53-b1f1-b0308bdf368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment: 1 = belief and claim point in same direction; 0 = misaligned\n",
    "df[\"Alignment\"] = (\n",
    "    ((df[\"BeliefClimateExists_num\"] > 0) & (df[\"ClaimStanceLabel_num\"] == 1)) |\n",
    "    ((df[\"BeliefClimateExists_num\"] < 0) & (df[\"ClaimStanceLabel_num\"] == 0))\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc51d18-5a83-47df-bc42-2e69e55efe3e",
   "metadata": {},
   "source": [
    "Simplify the model’s decision to a binary outcome (accept = 1, refute = 0). You can treat “Neutral” as missing or as 0.5 if you want to retain it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4bbb6c5d-e068-4bb8-ae62-f6904319de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Decision_binary\"] = df[\"ModelDecisionOfClaim\"].map({\"Accept\": 1, \"Refute\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25889160-75ca-4d03-930a-4b91bd578f24",
   "metadata": {},
   "source": [
    "Then comes the logistic regression.\n",
    "\n",
    "We model whether the model/persona **accepts** a displayed claim as a function of the alignment between its prior belief and the claim stance, and the strength of evidence:\n",
    "\n",
    "$$\n",
    "\\text{logit}\\big(P(\\text{Accept})\\big)\n",
    "= \\beta_0\n",
    "+ \\beta_1 \\text{Alignment}\n",
    "+ \\beta_2 \\text{EvidenceStrength}\n",
    "+ \\beta_3 \\big(\\text{Alignment} \\times \\text{EvidenceStrength}\\big)\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "- \\( \\text{Accept} \\): Binary outcome (1 = Accept, 0 = Refute)  \n",
    "- \\( \\text{Alignment} \\): 1 if belief and claim stance are consistent; 0 otherwise  \n",
    "- \\( \\text{EvidenceStrength} \\): Ordinal variable representing the strength of evidence  \n",
    "  (e.g., −1 = Refutes, 0 = Not Enough Info, +1 = Supports)  \n",
    "- \\( \\beta_3 \\): Interaction term capturing how evidence moderates confirmation bias  \n",
    "\n",
    "**Interpretation:**\n",
    "- \\( \\beta_1 > 0 \\): Aligned claims are more likely to be accepted (confirmation bias).  \n",
    "- \\( \\beta_2 > 0 \\): Stronger supporting evidence increases acceptance.  \n",
    "- \\( \\beta_3 < 0 \\): Strong evidence weakens confirmation bias (bias moderation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d467dc7b-7578-484b-9779-c7892eb2a42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540792\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Decision_binary   No. Observations:                18099\n",
      "Model:                          Logit   Df Residuals:                    18095\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Wed, 29 Oct 2025   Pseudo R-squ.:                  0.1686\n",
      "Time:                        13:36:25   Log-Likelihood:                -9787.8\n",
      "converged:                       True   LL-Null:                       -11772.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==================================================================================================\n",
      "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Intercept                          0.7419      0.024     31.361      0.000       0.696       0.788\n",
      "Alignment                         -0.0812      0.037     -2.214      0.027      -0.153      -0.009\n",
      "EvidenceStrength_num               1.3291      0.030     44.388      0.000       1.270       1.388\n",
      "Alignment:EvidenceStrength_num    -0.0826      0.046     -1.789      0.074      -0.173       0.008\n",
      "==================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Encode evidence strength ordinally\n",
    "df[\"EvidenceStrength_num\"] = df[\"EvidencesVerdict\"].map({\n",
    "    \"REFUTES\": -1,\n",
    "    \"NOT_ENOUGH_INFO\": 0,\n",
    "    \"SUPPORTS\": 1\n",
    "})\n",
    "\n",
    "# Drop NaN and fit logistic regression\n",
    "model = smf.logit(\n",
    "    \"Decision_binary ~ Alignment * EvidenceStrength_num\",\n",
    "    data=df.dropna(subset=[\"Decision_binary\", \"Alignment\", \"EvidenceStrength_num\"])\n",
    ").fit()\n",
    "\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.1 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
